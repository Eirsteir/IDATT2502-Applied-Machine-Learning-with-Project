{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "LTSM_emojis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\r\n",
        "print(dev)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QiunL9nUdUZ",
        "outputId": "ca43ae55-69b5-409e-dbaf-a1fc50c08630"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "emojis = {\r\n",
        "    'hat': '\\U0001F3A9',\r\n",
        "    'rat': '\\U0001F400',\r\n",
        "    'cat': '\\U0001F408',\r\n",
        "    'flat': '\\U0001F3E2',\r\n",
        "    'matt': '\\U0001F468',\r\n",
        "    'cap': '\\U0001F9E2',\r\n",
        "    'son': '\\U0001F466'\r\n",
        "}\r\n",
        "\r\n",
        "index_to_emoji = [value for _, value in emojis.items()]\r\n",
        "emojies = np.eye(len(emojis))\r\n",
        "emoji_encoding_size = len(emojies)\r\n",
        "\r\n",
        "index_to_char = [' ', 's', 'a', 'r', 'm', 'p', 'c', 't', 'f', 'h', 'l', 'n', 'o']\r\n",
        "char_encodings = np.eye(len(index_to_char))\r\n",
        "encoding_size = len(char_encodings)\r\n",
        "\r\n",
        "letters ={}\r\n",
        "\r\n",
        "for i, letter in enumerate(index_to_char):\r\n",
        "        letters[letter] = char_encodings[i]\r\n",
        "\r\n",
        "# Generate list of index to char\r\n",
        "# words = (\"hat \", \"rat \", \"cat \", \"flat \", \"matt \", \"cap \", \"son \")\r\n",
        "# letters = list(map(lambda w: list(w), words))\r\n",
        "# import functools\r\n",
        "# print(set(functools.reduce(lambda a, b: a + b, words)))\r\n",
        "\r\n",
        "x_train = torch.tensor([\r\n",
        "        [[letters['h']], [letters['a']], [letters['t']], [letters[' ']]],\r\n",
        "        [[letters['r']], [letters['a']], [letters['t']], [letters[' ']]],\r\n",
        "        [[letters['c']], [letters['a']], [letters['t']], [letters[' ']]],\r\n",
        "        [[letters['f']], [letters['l']], [letters['a']], [letters['t']]],\r\n",
        "        [[letters['m']], [letters['a']], [letters['t']], [letters['t']]],\r\n",
        "        [[letters['c']], [letters['a']], [letters['p']], [letters[' ']]],\r\n",
        "        [[letters['s']], [letters['o']], [letters['n']], [letters[' ']]],\r\n",
        "        ], \r\n",
        "        dtype=torch.float)\r\n",
        "\r\n",
        "y_train = torch.tensor([\r\n",
        "        [emojies[0], emojies[0], emojies[0], emojies[0]] ,\r\n",
        "        [emojies[1], emojies[1], emojies[1], emojies[1]],\r\n",
        "        [emojies[2], emojies[2], emojies[2], emojies[2]],\r\n",
        "        [emojies[3], emojies[3], emojies[3], emojies[3]],\r\n",
        "        [emojies[4], emojies[4], emojies[4], emojies[4]],\r\n",
        "        [emojies[5], emojies[5], emojies[5], emojies[5]],\r\n",
        "        [emojies[6], emojies[6], emojies[6], emojies[6]]], \r\n",
        "        dtype=torch.float)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7, 4, 1, 13])\n",
            "torch.Size([7, 4, 7])\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toZPm28_UzbD",
        "outputId": "0a587969-27dd-4332-b831-cb552b35116c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "class LongShortTermMemoryModel(nn.Module):\n",
        "    def __init__(self, encoding_size, emoji_encoding_size):\n",
        "        super(LongShortTermMemoryModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(encoding_size, 128)  # 128 is the state size\n",
        "        self.dense = nn.Linear(128, emoji_encoding_size)  # 128 is the state size\n",
        "\n",
        "    def reset(self):  # Reset states prior to new input sequence\n",
        "        zero_state = torch.zeros(1, 1, 128).to(dev)  # Shape: (number of layers, batch size, state size)\n",
        "        self.hidden_state = zero_state\n",
        "        self.cell_state = zero_state\n",
        "\n",
        "    def logits(self, x):  # x shape: (sequence length, batch size, encoding size)\n",
        "        out, (self.hidden_state, self.cell_state) = self.lstm(x, (self.hidden_state, self.cell_state))\n",
        "        return self.dense(out.reshape(-1, 128))\n",
        "\n",
        "    def f(self, x):  # x shape: (sequence length, batch size, encoding size)\n",
        "        return torch.softmax(self.logits(x), dim=1)\n",
        "\n",
        "    def loss(self, x, y):  # x shape: (sequence length, batch size, encoding size), y shape: (sequence length, encoding size)\n",
        "        return nn.functional.cross_entropy(self.logits(x), y.argmax(1))"
      ],
      "outputs": [],
      "metadata": {
        "id": "azS0gTjRUv46"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "model = LongShortTermMemoryModel(encoding_size, emoji_encoding_size).to(dev)\n",
        "\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
        "for epoch in range(500):\n",
        "    for i in range(x_train.size()[0]):\n",
        "        model.reset()\n",
        "        model.loss(x_train[i].to(dev), y_train[i].to(dev)).backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ],
      "outputs": [],
      "metadata": {
        "id": "AtnUm3b4U9qj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "def generate_emoji(string):\n",
        "    y = -1\n",
        "    model.reset()\n",
        "    for i in range(len(string)):\n",
        "        char_index = index_to_char.index(string[i])\n",
        "        y = model.f(torch.tensor([[char_encodings[char_index]]], dtype=torch.float).to(dev))\n",
        "    print(index_to_emoji[y.argmax(1)])\n",
        "\n",
        "generate_emoji('rt')\n",
        "generate_emoji('rats')\n",
        "generate_emoji(\"s\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üêÄ\n",
            "üêÄ\n",
            "üë¶\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW_4AidJZBUZ",
        "outputId": "6220a483-018d-4359-bb97-c65e18cfaff5"
      }
    }
  ]
}